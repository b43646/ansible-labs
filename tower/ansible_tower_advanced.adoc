= Lab: Ansible Tower for Advanced Users
:scrollbar:
:data-uri:
:toc: left
:numbered:
:icons: font
:imagesdir: ./images

// image::forum.jpg[]

== About this Lab

You have already used Ansible Automation quite a bit and have started to look into Tower? Or you are already using Tower? Cool. We prepared this lab to give a hands-on introduction to some of the more advanced features of Tower. Be prepared to learn about:

* Ansible Tower clustering
* The isolated node feature
* Ways to provide inventories (importing inventory, dynamic inventory)
* The Smart Inventory feature
* Some guide lines for structuring Ansible content

And over all of this we sprinkle a generous use of the Tower commandline client to save you from clicking in the web UI too much.

== Your Ansible Tower Lab Environment

In this lab you work in a pre-configured lab environment. You will have access to the following hosts:

[cols="v,v,v,v"]
|===
|Role|Hostname External (if applicable)|Hostname Internal|Internal IP

|Control/Jump Host, Gitea Repo|control-<GUID>.rhpds.opentlc.com|control.example.com|192.168.0.10
|Ansible Tower Cluster|\https://tower{1-3}-<GUID>.rhpds.opentlc.com|tower{1-3}.example.com|192.168.0.{4,5,6}0
|Ansible Tower Database Host||towerdb.example.com|192.168.0.70
|Managed RHEL7 Host 1||host1.example.com|192.168.0.20
|Managed RHEL7 Host 2||host2.example.com|192.168.0.30
|Ansible Tower Isolated Node||isonode.remote.example.com|172.16.0.10
|Managed Remote Host 1||isohost1.remote.example.com|172.16.0.20
|Managed Remote Host 2||isohost2.remote.example.com|172.16.0.30

|===

TIP: Your lab environment will get a unique *<GUID>*. You will be able to SSH into `control.example.com` using the external hostname `control-<GUID>.rhpds.opentlc.com`, from here you need to SSH into the other hosts to run tasks on the commandline. 

TIP: Ansible Tower has already been installed and licensed for you, the web UI will be reachable over HTTP/HTTPS. 

As you can see the lab environment is pretty extensive. You basically have one network segment with:

* A bastion/jump host you access via SSH, the Gitea git repo lives here as well
* Two managed RHEL 7 hosts
* A three-node Tower cluster with a separate DB host

And a second network segment with:

* One host that acts as a isolated Tower node
* Two hosts which act as remote managed nodes that can only be reached from/through the isolated node. (Direct access to the managed hosts is actually not blocked, but this is the scenario)

== Access your Lab Environment

include::access_grabber.adoc[]

== Introduction to Ansible Tower Clustering

With version 3.1 Ansible Tower introduced clustering, replacing the redundancy solution configured with the active-passive nodes. Clustering is sharing load between Tower nodes/instances. Each Tower instance is able to act as an entry point for UI and API access.

TIP: Using a load balancer in front of the Tower nodes is possible, but optional because an Ansible Tower cluster can be accessed via all Tower instances.

Each instance in a Tower cluster expands the cluster's capacity to execute jobs. Jobs can and will run anywhere rather than be directed on where to run.

TIP: The Appendix contains some installation considerations and an installer inventory for reference.

== Know your Cluster

=== Access the Tower Web UI

For the first contact to your cluster open your browser and login to all three nodes web UIs (you'll have to accept the self-signed certificates):

WARNING: Replace the *<REPL>* string with your GUID!

* *https://tower1-<REPL>.rhpds.opentlc.com*
* *https://tower2-<REPL>.rhpds.opentlc.com*
* *https://tower3-<REPL>.rhpds.opentlc.com*

Just from the web UI you wouldn't know you've got a Tower cluster at your hands here. To learn more about your cluster and it's state, in one of the instances web UI under *ADMINISTRATION* choose *Instance Groups*. Here you will get an overview of the cluster by instance groups. Explore the information provided, of course there is no capacity used yet and no Jobs have run.

From this view you can already see the instance count is three, click on *INSTANCES* to get more information about your cluster's Tower instances. In the instances view you can toggle nodes off/online and adjust the number of forks.

Note right now we have only one *INSTANCE GROUP* named *tower*. This is the default in a freshly installed Tower cluster, we'll extend this later.

=== Access you Tower Cluster via SSH

You can also get information about your cluster on the command line. In a terminal window, bring up an SSH session to your control host using the external hostname (replace the <GUID> string):

----
# ssh root@control-<GUID>.rhpds.opentlc.com
----


From `control.example.com` jump to one of the Tower instances, e.g.:

----
[root@control ~]# ssh tower1.example.com
----

And run the following command:

----
[root@tower1 ~]# awx-manage list_instances
[tower capacity=177]
  tower1.example.com capacity=59 version=3.4.1 heartbeat="2019-02-26 15:00:25"
  tower3.example.com capacity=59 version=3.4.1 heartbeat="2019-02-26 15:00:15"
  tower2.example.com capacity=59 version=3.4.1 heartbeat="2019-02-26 15:00:07"

----

So what we got is an three-node Tower cluster, no surprises here. In addition the command tells us the capacity (maximum number of forks/concurrent jobs) per node and for the whole cluster. 

TIP: The *awx-manage* (formerly tower-manage) utility can be used to administer a lot of the more internal aspects of Tower. You can e.g. use it to clean up old data, for token and session management and for cluster management.

== There is more to Tower then the Web UI

This is an advanced Tower lab so we don't really want you to use the web UI for everything. Tower's web UI is well done and helps with a lot of tasks, but same as in system administration it's often handy to be able to use the command line or scripts for certain tasks.

We've incorporated different ways to work with Tower in this lab guide and hope you'll find it helpful. The first step we do is install the *tower-cli* utility.

TIP: *tower-cli* is an open source project currently under development and, until a complete implementation occurs, only implements a subset of Towerâ€™s features. Right now you can install `tower-cli` from Python Pip or from the EPEL repository.

We'll install it on your control host using locally cached RPM packages. Exit the SSH session to *tower1.example.com* or open a new one to the control host, then install *tower-cli*:

----
# ssh root@control-<GUID>.rhpds.opentlc.com
[root@control ~]# yum install python2-ansible-tower-cli -y
----

After installing the tool, you have to do some basic configuration:

----
[root@control ~]# tower-cli config host tower2.example.com
[root@control ~]# tower-cli config username admin
[root@control ~]# tower-cli config password r3dh4t1!
----

TIP: It doesn't really matter what node you have it talking to.

Now test *tower-cli* is working. First run it without arguments to get a list of resources you can manage with it:

----
[root@control ~]# tower-cli --help
----

And then test something, e.g.:

----
[root@control ~]# tower-cli inventory list
----

TIP: When trying to find a *tower-cli* command line for something you want to do, just move one by one.

Example:

----
[root@control ~]# tower-cli --help
----

Okay, there is an *inventory* resource. Let's see...

----
[root@control ~]# tower-cli inventory --help
----

Well, *create* sounds like what I had in mind. But what arguments do I need? Just run:

----
[root@control ~]# tower-cli inventory create
----

Bingo! Take note of the *REQUIRED* mark.

TIP: When you start using *tower-cli* this file is very helpful as it provides a lot of examples: https://raw.githubusercontent.com/ansible/tower-cli/master/docs/source/cli_ref/examples/fake_data_creator.sh

=== Challenge Lab: tower-cli

To practice your *tower-cli* skills, here is a challenge:

* Try to change the *idle time out* of the Tower web UI, it's 1800 seconds by default. Set it to, say, 7200. Using *tower-cli*, of course.

* Start by looking for a resource type *tower-cli* provides using *--help* that sounds like it has something to do with changing config settings.

* Look at the available *tower-cli* commands for this resource type.

* Use the commands to have a look at the parameters settings and change it.

TIP: The configuration parameter is called *SESSION_COOKIE_AGE*

WARNING: *SOLUTION BELOW!*

----
[root@control ~]# tower-cli setting
[root@control ~]# tower-cli setting get SESSION_COOKIE_AGE
[root@control ~]# tower-cli setting modify SESSION_COOKIE_AGE 7200
[root@control ~]# tower-cli setting get SESSION_COOKIE_AGE
----

If you want to, go to the web UI and check the setting under *ADMINISTRATION->Settings->System*.

== Creating Inventory and Credentials

The next steps don't differ from what you would do with a single-instance Tower. To run Ansible jobs from Tower you need an inventory and machine credentials.

=== Create an Inventory

As said we don't want you to go to the web UI to configure your static inventory. I mean, if you really want to, go ahead. But here we'll use *tower-cli* to create a static inventory, we'll get to dynamic inventories later on.

First create the inventory in Tower using *tower-cli*. Try to get the proper invocation of *tower-cli* yourself and create an inventory name *Example Inventory* (yup, very creative, we know).

TIP: *tower-cli* behaves pretty UNIXy, just use *--help* to get down to the needed command.

WARNING: *Solution Below*!

----
[root@control ~]# tower-cli inventory create --name "Example Inventory" --organization "Default"
----

==== Add Hosts to the Inventory using *tower-cli*

Now that we have the empty inventory created, add your two managed hosts *host1.example.com* and *host2.example.com*, again using *tower-cli*.

TIP: Use *tower-cli* to get the resources you can use it on, then (in this case) *tower-cli host --help* and finally get the proper invocation help with *tower-cli host create --help*.

WARNING: *Solution Below*!

----
[root@control ~]# tower-cli host create --name "host1.example.com" --inventory "Example Inventory"
[root@control ~]# tower-cli host create --name "host2.example.com" --inventory "Example Inventory"
----

==== Add Hosts using *awx-manage*

It's fine to use *tower-cli* to add hosts but there is another way using the command line: *awx-manage* can add hosts by importing existing inventory files. Let's give this a try, too:

First create a new inventory named *Imported Inventory* using *tower-cli* on the control host or from the web UI:

----
[root@control ~]# tower-cli inventory create --name "Imported Inventory" --organization "Default"
----

Then open a SSH session to *tower1.example.com* (or one of the other nodes):

----
[root@control ~]# ssh tower1.example.com
----

On the Tower node create a file named *example_inventory* with a simple inventory:

----
host1.example.com
host2.example.com
----

Use *awx-manage* on the Tower node to add the hosts to your *Imported Inventory* inventory:

----
[root@tower1 ~]# awx-manage inventory_import --source=./example_inventory --inventory-name="Imported Inventory"

    1.808 INFO     Updating inventory 2: Example Inventory
    1.910 INFO     Reading Ansible inventory source: /root/example_inventory
    2.764 INFO     Processing JSON output...
    2.764 INFO     Loaded 0 groups, 2 hosts
    2.876 INFO     Inventory import completed for  (Example Inventory - 6) in 1.1s
----

Now go to the web UI of all three Tower nodes and check your *Example Inventory* and *Imported Inventory* exist and both contains the two hosts.

=== Create Machine Credentials

TIP: SSH keys have already been created and distributed in your lab environment and `sudo` has been setup on the managed hosts to allow password-less login for user *ansible* on *control.example.com*.

Now configure the credentials to access our managed hosts from Tower. As configuring credentials with SSH keys from *tower-cli* on the command line is a bit cumbersome, just this time use the web UI. In one of the Tower web UI under *RESOURCES -> Credentials*:


* Click the image:green_plus.png[20,20] button to add new credentials
* *NAME:* Example Credentials
* *ORGANIZATION:* Default
* *CREDENTIAL TYPE:* Machine
* *USERNAME:* ansible
* *PRIVILEGE ESCALATION METHOD:* sudo

As we are using SSH key authentication, you have to provide an SSH private key that can be used to access the hosts. You could also configure password authentication here.

* Bring up an SSH terminal on *control.example.com*, become user `ansible` and `cat` the SSH private key:
----
[root@control ~]# su - ansible
[ansible@control ~]$ cat .ssh/id_rsa
----

* Copy the complete private key (including "BEGIN" and "END" lines) and paste it into the *SSH PRIVATE KEY* field in the web UI.
* Click *SAVE*

You have now setup credentials to use later for your inventory hosts.

=== It's a Cluster After All

So far nothing special. But we are working in a clustered environment. Login to the other Tower instances Web UIs (the ones you didn't configured the inventory and credentials on). Have a good look around, everything we configured on one Tower instance was synced automatically to the other nodes. Inventory, credentials, all there.

== Run a Job in the Cluster

Before we can start jobs we need to configure some more things. This is again the same as in single-instance Tower deployments, so the guide will just walk you through the required steps. Take note how everything you configure is syncronized to the other nodes again.

Your lab environment includes Gitea, a Git-service that comes with a web ui and much more. Gitea runs on `control.example.com` and can be accessed via HTTP. Go and have a look around by accessing:

*\http://control-<GUID>.rhpds.opentlc.com/gitea*.

All repos on Gitea are configured as private e.g. you need to login to access the content. Log in as:

* *User*: git
* *Password*: r3dh4t1!

To configure and use this repository as a *Source Control Management (SCM)* system in Tower you have to:

* Create *Credentials* to access the Git repo
* Create a *Project* that uses the repository

=== Create SCM Credentials

First we have to create credentials again, this time to access the Git repository over HTTP. This credential is user/password based, so feel free to use the web UI again or find out how to use *tower-cli* to create it.

In the Tower web UI go to *Resources->Credentials*. Now:

* Click the image:green_plus.png[20,20] button to add new credentials
* *NAME*: Gitea Control
* *CREDENTIAL TYPE*: Choose *Source Control*

TIP: You will have to change the page in the *SELECT CREDENTIAL TYPE* window.

* *USERNAME*: git
* *PASSWORD*: r3dh4t1!
* Click *SAVE*

If you want to use *tower-cli*:

* Use the help function to find the needed arguments
* The credential type is "Source Control", as "inputs" you need "user" and "password"

WARNING: *SOLUTION BELOW!*

----
[root@control ~]# tower-cli credential create --credential-type="Source Control" \
                    --name="Gitea Credentials" \
                    --inputs='{"username": "git", "password": "r3dh4t1!"}' \
                    --organization="Default"
----
=== Create the Project

Now with the SCM credentials configured, either in the web UI or using *tower-cli* create a *Project* for one of your Gitea repositories.

==== In the web UI

* Go to *Projects* in the side menu view click the image:green_plus.png[20,20] button. Fill in the form:

* *NAME:* Apache
* *ORGANIZATION:* Default
* *SCM TYPE:* Git

Now you need the HTTP URL to access the repo. Go to the Gitea web UI, choose the *Apache* repository and copy the HTTP URL. Enter the URL into the Project configuration:

** *SCM URL:* \http://control.example.com/gitea/git/Apache.git
* *SCM CREDENTIAL:* Gitea Control
* *SCM UPDATE OPTIONS:* Tick all three boxes to always get a fresh copy of the repository and to update the repository when launching a job.
* Click *SAVE*

==== Or Using *tower-cli* on the control host

----
[root@control ~]# tower-cli project create --name="Apache" \
                    --scm-type=git \
                    --scm-url="http://control.example.com/gitea/git/Apache.git" \
                    --scm-credential="Gitea Credentials" \
                    --organization "Default" \
                    --scm-clean=true --scm-delete-on-update=true --scm-update-on-launch=true \
                    --wait
----

TIP: The new Project will be synced after creation automatically.

TIP: Remember you can use `control.example.com` as hostname in *SCM URL* because it resolves inside the environment. For accessing the Gitea web UI in your browser you need to use `\http://control-<GUID>.rhpds.opentlc.com/gitea`.

=== Create a Job Template

Before running an Ansible *Job* from your Tower cluster you must create a *Job Template*, again business as usual for Tower users.

==== In the Web UI

* Go to *Templates* in the *RESOURCES* section of the menu, click the image:green_plus.png[20,20] button and choose *Job Template*.

** *NAME:* Install Apache
** *JOB TYPE:* Run
** *INVENTORY:* Example Inventory
** *PROJECT:* Apache
** *PLAYBOOK:* apache_install.yml
** *CREDENTIAL:* Example Credentials
** We need to run the tasks as root so check *Enable privilege escalation*
** Click *SAVE*

==== Or Using *tower-cli*

----
[root@control ~]# tower-cli job_template create \
                    --name="Install Apache" \
                    --inventory="Example Inventory" \
                    --credential="Example Credentials" \
                    --project=Apache \
                    --playbook=apache_install.yml \
                    --become-enabled="yes"
----

=== Run a Job

Now you are ready to start a job in your Tower cluster. In the web UI's *Templates* view select the new Job Template and run it by clicking the rocket icon. Again this is at first not different from a standard Tower.

TIP: But as this is a cluster of active nodes every node could have run the job. And the Job output in Tower's web UI doesn't tell you where it run, just the instance group.

=== So what Instance run the Job? Check the Results!

==== Via command line and curl

But there is help. In one of the Tower instances web UI go to the *Instance Groups* menu item. For the `tower` instance group, the *TOTAL JOBS* counter shows the number of finished jobs. If you click *TOTAL JOBS* you'll get a detailed list of jobs.

To see on what instance a job actually run go back to the *Instance Groups* view. If you click *INSTANCES* under the Tower group, you will get an overview of the *TOTAL JOBS* each Tower instance executed which leads to the job list again.

But it would still be nice to see where a job run (not the other way round) and to get an idea how jobs are distributed to the available instances. For this we have to use the API.

To run a number of jobs (so the cluster has something to distribute) we could just fire of a couple of the Apache job templates, but doing this using the web UI is tiresome. So let's use *tower-cli* to run some jobs, what about just running the *Install Apache* Template five times?

----
[root@control ~]# for i in `seq 1 5`; do tower-cli job launch -J "Install Apache" ; sleep 5 ; done
----

And now query the API for the instance/node the jobs where executed on:

----
[root@tower2 ~]# curl -s -k -u admin:r3dh4t1! https://tower2.example.com/api/v2/jobs/ | python -m json.tool | grep execution_node
            "execution_node": "tower3.example.com",
            "execution_node": "tower1.example.com",
            "execution_node": "tower3.example.com",
            "execution_node": "tower2.example.com",
            "execution_node": "tower2.example.com",
----

Now you can see how the Tower cluster distributed the jobs between the instances! And for the fun of it you can of course change the Tower instance to query in the `curl` command and see that you get the same information.

==== Via API in the browser

The Tower API can also be queried in the browser. For example to have a look at the job details (basically what you did above using curl and friends):

* Find the job you just executed in *\https://tower1-<GUID>.rhpds.opentlc.com/#/jobs* and remember the job number. 
* Now get the job details via the API interface: open the URL *\https://tower1-<GUID>.rhpds.opentlc.com/api/v2/jobs/<NUMBER>/* where `<NUMBER>` is the number of the job you just looked up in the UI. 
* Search the page for the string you are interested in, e.g. `execution_node`, the tower instance on which the job was executed is listed there.

TIP: You can of course query any Tower node.

== Tower Instance Groups

Ansible Tower clustering allows you to easily add capacity to your Tower infrastructure by adding nodes. What it doesn't allow is to dedicate capacity or nodes to a purpose, be it a group of people, a department or a location. 

In a single-group Tower cluster where all nodes are within the `tower` group there is no way to influence what node will run a job, as you saw the cluster will take care of scheduling Jobs on nodes as it sees fit.

To enable more control over what node is running a job, Tower 3.2 saw the introduction of the instance groups feature. Instance groups allow you to organize your cluster nodes into groups. In turn Jobs can be assigned to Instance Groups by configuring the Groups in Organizations, Inventories or Job Templates.

TIP: The order of priority is *Job Template > Inventory > Organization*. So Instance Groups configured in Job Templates take precedence over those configured in Inventories, which take precedence over Organizations

Some things to keep in mind about Instance Groups:

* Nodes in an Instance Group share a job queue
* You can have as many Instance Groups as you like as long as there is at least one node in the `tower` group
* Nodes can be in one or more Instance Groups
* Group can not be named `instance_group_tower`!
* Tower instances can't have the same name as a group

This allows for some pretty cool setups, e.g. you could have some nodes shared over the whole cluster (by putting them into all groups) but then have other nodes that are dedicated to one group to reserve some capacity.

WARNING: The base `tower` group does house keeping like processing events from jobs for all groups so the node count of this group has to scale with your overall cluster load, even if these nodes are not used to run Jobs.

Talking about the `tower` group: As you have learned this group is crucial for the operations of a Tower cluster. Apart from the house keeping tasks, if a resource is not associated with an Instance Group, one of the nodes from the `tower` group will run the Job. So if there are no operational nodes in the base group, the cluster will not be able to run Jobs.

WARNING: It is important to have enough nodes in the `tower` group

TIP: Here is a really great blog post going into Instance Groups with a lot more depth: https://www.ansible.com/blog/ansible-tower-feature-spotlight-instance-groups-and-isolated-nodes.

=== Creating Instance Groups

Having the introduction out of the way, let's get back to our lab and give Instance Groups a try. First have a look at our setup as described in the installers inventory file. In your SSH session on the control host change into the Ansible installer directory and do the following:

----
[root@control ~]# cd ansible-tower-setup-bundle-3.4.1-1.el7/
[root@control ansible-tower-setup-bundle-3.4.1-1.el7]# cat inventory
[tower]
tower1.example.com
tower2.example.com
tower3.example.com

[database]
towerdb.example.com

[...]
----

In this basic cluster setup we just have the `tower` base group. Let's configure two new Instance groups and add Tower instances. As an example scenario we'll take one node out of the `tower` group and share another node between groups.

WARNING: This is not best practice, it's just for the sake of this lab! Any jobs that are launched targeting a group without active nodes will be stuck in a waiting state until instances become available. So one-instance groups are never a good idea.

The global tower group can still be associated with a resource. This can be used to specify a preferred instance group on the job template or inventory, but still allow the job to be submitted to any instance if the Tower(s) of the preferred group are out of capacity.

TIP: Instance groups are prefixed with `instance_group_`. 

Using your favorite editor adapt the `inventory` file to add the inventory groups. Afterwards it should look like this:

----
[tower]
tower1.example.com
tower2.example.com

[instance_group_prod]
tower3.example.com

[instance_group_dev]
tower2.example.com

[database]
towerdb.example.com

[all:vars]
ansible_become=true

admin_password='r3dh4t1!'

pg_host='towerdb.example.com'
pg_port='5432'

pg_database='tower'
pg_username='tower'
pg_password='r3dh4t1!'

rabbitmq_port=5672
rabbitmq_vhost=tower
rabbitmq_username=tower
rabbitmq_password='r3dh4t1!'
rabbitmq_cookie=rabbitmqcookie

# Isolated Tower nodes automatically generate an RSA key for authentication;
# To disable this behavior, set this value to false
# isolated_key_generation=true
----

WARNING: Make sure you only change the groups above the `[database]` section!

After editing the inventory, you are ready to run he installer to make the desired changes. But before have a look at the instance groups using *tower-cli*:

----
[root@control ~]# tower-cli instance_group list
== ===== ======== =================
id name  capacity consumed_capacity
== ===== ======== =================
 1 tower      171                 0
== ===== ======== =================
----

Okay, now start the Tower installer to create the instance groups. This can take a couple of minutes, just sit back and enjoy the show.

----
[root@control ansible-tower-setup-bundle-3.4.1-1.el7]# ./setup.sh
----

=== Verify Instance Groups

After the installer has finished, verify the instance groups where created as planned. This can be done using different ways.

==== Via cli

----
[root@control ansible-tower-setup-bundle-3.4.1-1.el7]# tower-cli instance_group list
== ===== ======== ================= 
id name  capacity consumed_capacity 
== ===== ======== ================= 
 1 tower      171                 0
 2 prod        57                 0
 3 dev         57                 0
== ===== ======== =================
----

==== Via API

You can again query the API to get this information. Either use the browser to access the URL `\https://tower1-REPL.rhpds.opentlc.com/api/v2/instance_groups/` or use curl to access the API from the command line:

----
[root@control ~]# curl -s -k -u admin:r3dh4t1! https://tower2.example.com/api/v2/instance_groups/| python -m json.tool
{
    "count": 1,
    "next": null,
    "previous": null,
    "results": [
        {
            "capacity": 171,
            "committed_capacity": 0,
            "consumed_capacity": 0,
            "controller": null,
            "created": "2019-03-01T16:39:08.293548Z",
            "id": 1,
            "instances": 3,
            "jobs_running": 0,
            "jobs_total": 150,
            "modified": "2019-03-01T16:39:08.343125Z",
            "name": "tower",
            "percent_capacity_remaining": 100.0,
            "policy_instance_list": [
                "tower3.example.com",
                "tower1.example.com",
                "tower2.example.com"
            ],
            "policy_instance_minimum": 0,
            "policy_instance_percentage": 0,
            "related": {
                "instances": "/api/v2/instance_groups/1/instances/",
                "jobs": "/api/v2/instance_groups/1/jobs/"
            },
            "type": "instance_group",
            "url": "/api/v2/instance_groups/1/"
        }
    ]
}
----

==== Via the Web UI

Open the URL `\https://tower1-<GUID>.rhpds.opentlc.com/#/instance_groups` in your browser.

In the *INSTANCE GROUPS* overview all instance groups are listed with details of the group itself like number of instances in the group, running jobs and finished jobs. Like you've seen before for the *tower* global group the current capacity of the instance groups is shown in a live view, thus providing a quick insight if there are capacity problems.

=== Deactivating Tower Instances

While in the *INSTANCES GROUPS* overview click the *INSTANCES* link for, say, the *dev* group. In the next view you'll see a slide button next to each Tower instance (only one in this case). 

* The button should be set to "ON" image:on_off.png[20,20]. Clicking it would deactivate the corresponding instance and would prevent that further jobs are assigned to it. 
* Running jobs on an instance which is set to "OFF" are finished in a normal way. 
* Further to the right a slider can change the amount of RAM and thus the amount of forks scheduled on an instance. This way it is possible to influence in which ratio the jobs are assigned.

== Start Parallel Jobs across Instances

The real power of the instance groups is revealed when multiple jobs are started, and they are assigned to different Tower nodes. To launch multiple jobs we will set up a workflow with multiple concurrent jobs. 

=== Lab Scenario

During this lab we'll focus on security compliance according to STIG, CIS and so on. Often these compliance rules are enforced by executing an Ansible task per each requirement. This makes documentation and audit easier. 

Compliance requirements are often grouped into independent categories. The tasks of those can often be executed in parallel because they do not conflict with each other. 

In our demo case we use three playbooks which:

* ensure the absence of a few packages (STIG)
* ensure configuration of PAM and login cryptography (STIG)
* ensure absence of services and kernel modules (CIS).

The Playbooks can be found in the "compliance" repository on Gitea: `\http://control-<GUID>.rhpds.opentlc.com/gitea/git/compliance`. Head over to Gitea's web UI and have a look at the Playbooks to see what they do.

=== Prepare the Compliance Lab

==== First Step: Add Repository to Tower

The compliance repository needs to be added as project. Feel free to use the web UI or use *tower-cli* like shown below.

----
[root@control ~]# tower-cli project create -n "Compliance Repository" \
                    --organization Default \
                    --scm-type git \
                    --scm-url http://control.example.com/gitea/git/compliance.git \
                    --scm-clean 1 \
                    --scm-update-on-launch 1 \
                    --scm-credential "Gitea Credentials"
----

TIP: Again it should be obvious using tower-cli is much faster then clicking through multiple steps in a web interface.

Have a look at the status of the Project:

----
[root@control ~]# tower-cli project status -n "Compliance Repository"
----

==== Second Step: Create three Templates

As mentioned the repository contains three Playbooks to enforce different compliance requirements. To avoid clicking too much we again create these three templates via `tower-cli`:

----
[root@control ~]# tower-cli job_template create -n "Compliance STIG packages" \
                    --job-type run -i "Example Inventory" \
                    --project "Compliance Repository" \
                    --playbook "stig-packages.yml" \
                    --credential "Example Credentials" \
                    --become-enabled 1
----

----
[root@control ~]# tower-cli job_template create -n "Compliance STIG config" \
                    --job-type run -i "Example Inventory" \
                    --project "Compliance Repository" \
                    --playbook "stig-config.yml" \
                    --credential "Example Credentials" \
                    --become-enabled 1
----

----
[root@control ~]# tower-cli job_template create -n "Compliance CIS" \
                    --job-type run -i "Example Inventory" \
                    --project "Compliance Repository" \
                    --playbook "cis.yml" \
                    --credential "Example Credentials" \
                    --become-enabled 1
----

=== Create Parallel Workflow

To enable parallel execution of the tasks in these job templates, we will create a workflow. Workflows are configured in the *Templates* view, you might have noticed you can choose between *Job Template* and *Workflow Template* when adding a template.

* Go to the *Templates* view and click the image:green_plus.png[20,20] button. This time choose *Workflow Template*
** *NAME:* Compliance Workflow
** *ORGANIZATION:* Default
* Click *SAVE*
* Now the *WORKFLOW VISUALIZER* button becomes active, click it to start the graphical editor.
* Click on the *START* button, a new node opens. To the right you can assign an action to the node, you can choose between *JOBS*, *PROJECT SYNC* and *INVENTORY SYNC*.
* In this lab we'll link multiple jobs to the *START*, so select the *Compliance STIG package* job and click *SELECT*. The node gets annotated with the name of the job.
* Click on the *START* button again, another new node opens.
* Select the *Compliance STIG config* job and click *SELECT*. The node gets annotated with the name of the job.
* Click on the *START* button again, another new node opens.
* Select the *Compliance CIS* job and click *SELECT*. The node gets annotated with the name of the job.
* Click *SAVE*

You have configured a Workflow that is not going through templates one after the other but rather executes three templates in parallel.

=== Execute and Watch

Your workflow is ready to go, launch it.

* In the *Templates* view launch the *Compliance Workflow* by clicking the rocket icon.
* Wait until the job has finished.

Go to the *INSTANCE GROUPS* view and find out how the jobs where distributed over the instances:

* Open the *INSTANCES* view of the tower instance group.
* Look at the *TOTAL JOBS* view of the three instances
* Because the Job Templates called in the workflow didn't specify an instance group, they where distributed evenly over the instances. 

Now deactivate instance *tower1.example.com* with the image:on_off.png[20,20] button and wait until it is shown as deactivated. Go back to the list of templates and launch the workflow *Compliance Workflow* again.

Go back to *INSTANCE GROUPS*, get back to the instance overview of instance group *tower* and verify that the three Playbooks are launched on the missing instances.

Activate *tower1.example.com* again by pressing image:on_off.png[20,20] a second time.

=== Using Instance Groups

So we have seen how a Tower cluster is distributing jobs over Tower instances by default. We have already created instance groups which allow us to take control over what job is executed on which node, so let's use them.

To make it easier to spot where the jobs where run let's first empty the jobs history. This can be done using *awx-manage* on one of the Tower instances. From your control node SSH into one of the Tower hosts and run the command:

----
[root@tower1-REPL ~]# awx-manage cleanup_jobs  --days=0
----

==== Assign Jobs to Instance Groups

One way to assign a job to an instance group is in the job template. As our compliance workflow uses three job templates, do this for all of them:

* In the web UI, go to *RESOURCES->Templates*
* Open one of the three templates
* In the *INSTANCE GROUPS* field, choose the *dev* instance group and click *SAVE*.
* Click *SAVE* for the template and do this for the other compliance templates, too.

Now the jobs that make up our *Compliance Workflow* are all configured to run on the instances of the *dev* instance group.

==== Run

You have done this a couple of times now, you should get along without detailed instructions.

* Run the *Compliance Workflow* 
* What would you expect? On what instance(s) should the workflow jobs run?
* Verify!

TIP: *Result:* The workflow and the associated jobs will run on *tower2.example.com*. Okay, big surprise, in the *dev* instance group is only one instance.

But what's going to happen if you disable this instance?

* Disable the *tower2.example.com* instance in the *Instance Groups* view.
* Run the workflow again.
* What would you expect? On what instance(s) should the workflow jobs run?
* Verify!

TIP: *Result:* The workflow and the associated jobs will stay in pending state because there are no instance available in the *dev* instance group.

What's going to happen if you enable the instance again?

* Go to the *Instance Groups* view and enable *tower2.example.com* again.
* Check in the *Jobs* and *Instance Groups* view what's happening.

TIP: *Result:* After the instance is enabled again the jobs will pickup and run on *tower2.example.com*.

== Isolated Nodes

Ansible is used to manage complex infrastructures with machines and networks living in multiple separate datacenters, servers behind firewalls or in cloud VPCs and remote locations only reachable over unstable links which may not survive the length of a job run. In cases like these it's often better to run automation local to the nodes.

To solve this, Tower provides Isolated Nodes:

* Isolated nodes *don't have a full installation of Tower*, but a minimal set of utilities used to run jobs.
* It can be deployed behind a firewall/VPC or in a remote datacenter, only *ingress SSH traffic* from a *controller* instance to the *isolated* instances is required. 
* When a job is run that targets things managed by the isolated node, the *job* and its *environment* will be *pushed to the isolated node* over SSH
* Periodically, the *master Ansible Tower cluster will poll the isolated node* for status on the job. 
* When the *job finishes*, the job status will be *updated in Ansible Tower*

=== Setting Up Isolated Nodes

Isolated nodes are defined in the inventory file (same as instance groups) and setup by the Ansible Tower installer. Isolated nodes make up their own instance groups that are specified in the inventory file prefixed with *isolated_group_*. In the isolated instance group model, only specific *controller* Tower instance groups interact with *isolated* nodes.

 

So for the fun of it, let's set one up.

First have a look at our setup as described in the installers inventory file. In your SSH session on the control host change into the Ansible installer directory and do the following:

----
[root@control ~]# cd ansible-tower-setup-bundle-3.4.1-1.el7
[root@control ansible-tower-setup-bundle-3.4.1-1.el7]# cat inventory
[tower]
tower1.example.com
tower2.example.com

[instance_group_prod]
tower3.example.com

[instance_group_dev]
tower2.example.com

[database]
towerdb.example.com

[...]
----

We have the `tower` base group and two instance groups. For the isolated node we will define a new *isolated_group_* named *dmz* with one entirely new node (plain RHEL 7 for now), called `isonode.remote.example.com` which we'll use to manage other hosts in the remote location. Add the node to the inventory:

TIP: Changes are shown in *bold* type for clarity only!

[subs=+quotes]
----
[tower]
tower1.example.com
tower2.example.com

[instance_group_prod]
tower3.example.com

[instance_group_dev]
tower2.example.com

*[isolated_group_dmz]
isonode.remote.example.com

[isolated_group_dmz:vars]
controller=tower*

[database]
towerdb.example.com

[...]
----

TIP: Each isolated group must have a controller variable set. This variable points to the instance group that manages tasks that are sent to the isolated node. That instance group will be responsible for starting and monitoring jobs on the isolated node. In this case, we're using the main *tower* instance group to manage this isolated group.

After editing the inventory, start the installer to make the desired changes:

----
[root@control ansible-tower-setup-bundle-3.2.5-1.el7]# ./setup.sh
----

TIP: During installation of an isolated node, a randomized RSA key is generated and distributed as an authorized key to all *isolated* instances.

=== Verify Isolated Nodes

Isolated groups can be listed in the same way like instance groups and Ansible Tower cluster configuration. So the methods listed above discussing instance groups also show the isolated node. For example, using `tower-cli`:

[subs=+quotes]
----
[root@control ~]# tower-cli instance_group list
== ======== ======== =================
id   name   capacity consumed_capacity
== ======== ======== =================
 1 tower         171                 0
 2 prod           57                 0
 3 dev            57                 0
 *4 dmz             0                 0*
== ======== ======== =================
----

Like other instance groups, isolated node groups can be assigned at the level of an organization, an inventory, or an individual job template.

=== Create Isolated Node specific Inventory

Let's assume we have a DMZ setup with two hosts siloed off from the rest of the infrastructure called *isohost{1,2}.remote.example.com*. The isolated node we configured above is set in the same DMZ and is able to connect to the siloed hosts.

Now create a new inventory in your Tower cluster. You can do this with `tower-cli` like we did above, or you use the web UI. Why not use the web UI this time?

In the Tower web UI under *RESOURCES*, click *Inventories*:

* Click the image:green_plus.png[20,20] button to add a new inventory
* *NAME:* Remote Inventory
* *ORGANIZATION:* Default
* *INSTANCE GROUPS:* Pick the instance group you created in the last step, `dmz`
* Click *SAVE*

After you've clicked *SAVE*, you can add hosts: the button for the hosts management image:tower_hosts.png[40,40] is active now. Click on it to access the hosts overview. There are no hosts right now, so let's add some:

* Click the image:green_plus.png[20,20] button to add a new host
* *NAME:* `isohost1.remote.example.com`
* Click *SAVE*

Repeat the steps for a second host called `isohost2.remote.example.com`.

=== Create Template for Isolated Node

Next we need to assign a template to the nodes. Since those nodes are in a dmz, we certainly have to ensure their compliance. Thus we are going to make sure that they are following our CIS guidelines - and will set up a template executing the CIS playbook on them.

Go to *Templates* in the *RESOURCES* section of the menu, click the image:green_plus.png[20,20] button and choose *Job Template*.

* *NAME:* Remote CIS Compliance
* *JOB TYPE:* Run
* *INVENTORY:* Remote Inventory
* *PROJECT:* Compliance Repository
* *PLAYBOOK:* `cis.yml`
* *CREDENTIAL:* Example Credentials
* *INSTANCE GROUPS:* `dmz`
* We need to run the tasks as root so check *Enable privilege escalation*
* Click *SAVE*

Next, launch the template:

* In the *Templates* view launch the *Remote CIS Compliance* job by clicking the rocket icon.
* Wait until the job is finished.

=== Verify Results

Last but not least, let's check that the job was indeed executed by the isolated node `isonode.remote.example.com`: go to *Instance Groups* in the *ADMINISTRATION* section of the menu, click on *dmz*. There, click on the jobs button on top, and see the executed job.

== Advanced Inventories

=== Dynamic Inventories

Quite often just using static inventories will not be enough. You might be dealing with ever-changing cloud environments or you have to get your managed systems from a CMDB or other sources of truth.

Tower includes built-in support for syncing dynamic inventory from cloud sources such as Amazon AWS, Google Compute Engine, among others. Tower also offers the ability to use custom scripts to pull from your own inventory source.

In this chapter you'll get started with dynamic inventories in Tower. Aside from the build-in sources you can write inventory scripts in any programming/scripting language that you have installed on the Tower machine. To keep it easy we'll use a simple custom inventory script using... the Bash shell.

==== The Inventory Source

First you need a source. In real life this would be your cloud provider, your CMDB or what not. For the sake of this lab we have the web server on control.example.com configured to be our source.

Open an SSH session from the control host to one of your Tower-Nodes and query your external inventory source:

----
[root@tower1-REPL ~]# curl control.example.com:/pub/inventory_list
{
    "dyngroup":{
        "hosts":[
            "cloud1.cloud.example.com",
            "cloud2.cloud.example.com"
        ],
        "vars":{
            "var1": true
        }
    },
    "_meta":{
        "hostvars":{
            "cloud1.cloud.example.com":{
                "type":"web"
            },
            "cloud2.cloud.example.com":{
                "type":"database"
            }
        }
    }
}
----

Well, this is handy, the output is already configured as JSON like Ansible would expect... ;-) Okay, seriously, in real life your script would likely get some information from your source system, format it as JSON and return the data to Tower.

==== The Custom Inventory Script

An inventory scripts has to follow some conventions. It must accept the *--list* and *--host <hostname>* arguments. When it is called with *--list*, the script must output a JSON-encoded data containing all groups to be managed. When called with *--host <hostname>* it must return an JSON-formatted hash or dictionary of host variables (can be empty).

As looping over all hosts and calling the script with *--host* can be pretty slow, it is possible to return a top level element called "_meta" with all of the host variables in one script run. And this is what we'll do. So this is our custom inventory script:

----
#!/bin/bash

if [ "$1" == "--list" ] ; then
  curl control.example.com:/pub/inventory_list
elif [ "$1" == "--host" ]; then
  echo '{"_meta": {"hostvars": {}}}'
else
  echo "{ }"
fi
----

What it basically does is to return the data collected by curl when called with *--list* and as the data includes *_meta* information about the host variables Ansible will not call it with *--host*. The curl command is of course the place where your script  would get data by whatever means, format it as proper JSON and return it.

As simple as it gets, right? More information can be found https://docs.ansible.com/ansible/latest/dev_guide/developing_inventory.html[here]

So now you have a source of (slightly faked) inventory data and a script to fetch and pass it to Tower. Now you need to get this into Tower.

==== Integrate into Tower

The first step is to add the inventory script to Tower:

* In the web UI, open *RESOURCES->Inventory Scripts*.
* To create a new custom inventory script, click the image:green_plus.png[20,20] button.
* Fill in the needed data:
** *NAME:* Cloud Inventory
** Copy the Bash script from above and paste it into the *CUSTOM SCRIPT* field
* Click *SAVE*

Finally the new inventory script can be used in an actual *Inventory*.

* Go to *RESOURCES->Inventories*
* Click the image:green_plus.png[20,20] button and choose *Inventory*.
* *NAME:* Cloud Inventory
* Click *SAVE*
* Click the *SOURCES* button on top, the image:green_plus.png[20,20] to add a new source
* *NAME:* Cloud Custom Script*
* From the *SOURCE* drop-down choose *Custom Script*
* Now the dialog for the source opens, your custom script should already be selected in the *CUSTOM INVENTORY SCRIPT*.
* Under *UPDATE OPTIONS* check *Overwrite* and *Overwrite Variables*
* Click *SAVE*

To sync your new source into the inventory:

* Open the *Cloud Inventory* again
* Click the *SOURCES* button
* To the left click the circular arrow to start the sync process for your custom source.
* After the sync has finished click the *HOSTS* button.

You should now see a list of hosts according to what you got from the curl command above. Click the hosts to make sure the host variables are there, too.

==== Now to the Dynamic Part...

To mimic the dynamic nature of the inventory, adapt the file we are using as source.

* Open an SSH session to your control host (if it's not open anyway).
* Edit the file `/var/www/html/pub/inventory_list` to look like this (i.e. add another host):

----
{
    "dyngroup":{
        "hosts":[
            "cloud1.cloud.example.com",
            "cloud2.cloud.example.com",
            "cloud3.cloud.example.com"
        ],
        "vars":{
            "var1": true
        }
    },
    "_meta":{
        "hostvars":{
            "cloud1.cloud.example.com":{
                "type":"web"
            },
            "cloud2.cloud.example.com":{
                "type":"database"
            },
            "cloud3.cloud.example.com":{
                "type":"database"
            }
        }
    }
}
----

After saving the file:

* Go back to web UI, open the *Cloud Inventory* inventory
* Click the *SOURCES* button and re-sync the *Cloud Custom Script* source.
* Open the *HOSTS* view again and make sure you have three hosts listed.




== Appendix

=== Setup Considerations

Here are a number of things to consider when planning a clustered Tower deployment:

* The PostgreSQL database is a central component of the cluster. Ansible Tower is not taking care of availabilty, redundancy or replication of the database, this has to be configured "outside" of Tower.
* The number of instances in a cluster should always be an *odd number* and a minimum number of three is strongly recommended with a maximum of 20.
* RabbitMQ is a core component, so a lot of the requirements are dictated by it. Like e.g. the odd node count for quorum...
* Typical cluster considerations apply: All nodes need to be able to reliably connect to each other, stable address/hostname resolution, geographically co-located with reliable low-latency connections between instances.
* Remember there is no concept of primary/secondary instance, all systems are primary.

==== Installing an Ansible Tower Cluster

For initial configuration of a Tower cluster and for adding new instances the default Ansible installer is used, but the inventory file needs to be extended. Some important basic concepts:

* There has to be at least an inventory group named `tower`. We'll cover instance groups later, but keep in mind the nodes in this group are responsible for housekeeping tasks like where to launch jobs or to process playbook events.
* If all Tower instances in this group fail, jobs might not run and playbook events might not get written. So make sure there are enough instances in this group.
* The database can be installed and configured by the installer by adding the host to the `database` group. If the database host is provisioned separately, leave the group empty.

==== The Installer Inventory File

In this lab a three node Ansible Tower cluster is provided ready to go as installing it would eat too much of your lab time. It's pretty straight forward anyway. The inventory file here is just for giving you an idea what you are using here and for reference.

TIP: Keep in mind when working with clustered Ansible Tower that the database will not be clustered or replicated by the installer. This is something you have to take care of yourself.

----
[tower]
tower1.example.com
tower2.example.com
tower3.example.com

[database]
towerdb.example.com

[all:vars]
ansible_become=true

admin_password='r3dh4t1!'

pg_host='towerdb.example.com'
pg_port='5432'

pg_database='tower'
pg_username='tower'
pg_password='r3dh4t1!'

rabbitmq_port=5672
rabbitmq_vhost=tower
rabbitmq_username=tower
rabbitmq_password='r3dh4t1!'
rabbitmq_cookie=rabbitmqcookie
----

WARNING: In this lab this has been taken care of, but remember all instances have to able to resolve all hostnames and to reach each other!





























